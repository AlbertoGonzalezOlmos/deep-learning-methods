{"cells":[{"cell_type":"markdown","metadata":{},"source":["# OpenCV Library\n","\n","Basic image processing.\n"]},{"cell_type":"markdown","metadata":{},"source":["Image processing and computer vision tasks include displaying, cropping, flipping, rotating,  image segmentation, classification, image restoration,  image recognition, image generation.  "]},{"cell_type":"markdown","metadata":{},"source":["<ul>\n","    <li>In this notebook:\n","        <ul>\n","            <li>Importing and getting information about images   </li>\n","            <li>Histograms, Intensity Transformations  </li>\n","            <li>Geometric Transformations</li>\n","            <li>Spatial Filtering </li>\n","        </ul>\n","    </li>\n","    \n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n"]},{"cell_type":"markdown","metadata":{},"source":["Images used in the notebook:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/barbara.png -O barbara.png  "]},{"cell_type":"markdown","metadata":{},"source":["Helper function to concatenate two images side-by-side. "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def get_concat_h(im1, im2):\n","    #https://note.nkmk.me/en/python-pillow-concat-images/\n","    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n","    dst.paste(im1, (0, 0))\n","    dst.paste(im2, (im1.width, 0))\n","    return dst"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["my_image = \"lenna.png\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\Alberto\\\\Desktop\\\\github\\\\deep-learning-methods'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# checking current path\n","import os\n","cwd = os.getcwd()\n","cwd "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\Alberto\\\\Desktop\\\\github\\\\deep-learning-methods\\\\lenna.png'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# checking path of the image\n","image_path = os.path.join(cwd, my_image)\n","image_path\n"]},{"cell_type":"markdown","metadata":{},"source":["### `Importing and getting information about images`\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import cv2"]},{"cell_type":"markdown","metadata":{},"source":["The <code>imread()</code> method loads an image from the specified file, the input is the <code>path</code> of the image to be read, the <code>flag</code> paramter specifies how the image should be read, and the default value is <code>cv2.IMREAD_COLOR</code>.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["image = cv2.imread(my_image)\n","\n","# to load the image using the path\n","# image = cv2.imread(image_path)\n","# image.shape"]},{"cell_type":"markdown","metadata":{},"source":["The result is a numpy array with intensity values as 8-bit unsigned integers. \n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["type(image)"]},{"cell_type":"markdown","metadata":{},"source":["Shape of the array from the `shape` attribute.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(512, 512, 3)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["image.shape"]},{"cell_type":"markdown","metadata":{},"source":["Other libraries such as PIL return images in (R, G, B) format whereas OpenCV returns in (B, G, R) format.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["255"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["image.max()"]},{"cell_type":"markdown","metadata":{},"source":["and\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["3"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["image.min()"]},{"cell_type":"markdown","metadata":{},"source":["OpenCV's `imshow` function can open images in a new window, but this may bring problems in Jupyter:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#cv2.imshow('image', imgage)\n","#cv2.waitKey(0)\n","#cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["Using the `imshow` function from the `matplotlib` library:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Changing the color space with conversion code and the function `cvtColor` from the `cv2` library:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Grayscale images have pixel values representing the amount of light or intensity. Light shades of gray have a high-intensity darker shades have a lower intensity. White has the highest intensity, and black the lowest. \n","\n","To convert an image to Gray Scale using a color conversion code there is the function <code>cvtColor</code> and the parameter <code>cv2.COLOR_BGR2GRAY</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"]},{"cell_type":"markdown","metadata":{},"source":["The image array has only two dimensions, i.e. only one color channel:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_gray.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to save the grayscale image\n","cv2.imwrite('lena_gray_cv.jpg', image_gray)"]},{"cell_type":"markdown","metadata":{},"source":["To load a grayscale image `cv2.imread()` needs the gray color conversation code <code>cv2.COLOR_BGR2GRAY</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_gray = cv2.imread('barbara.png', cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"markdown","metadata":{},"source":["Working with different color channels.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon=cv2.imread('baboon.png')\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Getting the separate RGB channels and assigning them to the variables <code>blue</code>, <code>green</code>, and <code>red</code>, in (B, G, R) format.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["blue, green, red = baboon[:, :, 0], baboon[:, :, 1], baboon[:, :, 2]"]},{"cell_type":"markdown","metadata":{},"source":["Concatenating each image channel using the function <code>vconcat</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_bgr = cv2.vconcat([blue, green, red])"]},{"cell_type":"markdown","metadata":{},"source":["Plotting the color image next to the red channel in grayscale.\n","Regions with red have higher intensity values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.title(\"RGB image\")\n","plt.subplot(122)\n","plt.imshow(im_bgr,cmap='gray')\n","plt.title(\"Different color channels  blue (top), green (middle), red (bottom)  \")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can use numpy slicing to return the first 256 rows corresponding to the top half of the image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rows = 256"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image[0:rows,:,:])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Or to the first 256 columns corresponding to the left half of the image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["columns = 256"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image[:,0:columns,:])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["To reassign an array to another variable, use the `copy` method."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["A = new_image.copy()\n","plt.imshow(A)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["If the method `copy()` is not applyied, the variable will point to the same location in memory.\n"]},{"cell_type":"markdown","metadata":{},"source":["Manipulating elements by index. Below, the red channel of the new array `baboon_red` is set to zero making the image look red.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon_red = baboon.copy()\n","baboon_red[:, :, 0] = 0\n","baboon_red[:, :, 1] = 0\n","plt.figure(figsize=(10, 10))\n","plt.imshow(cv2.cvtColor(baboon_red, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### `Histograms, Intensity Transformations`  \n"]},{"cell_type":"markdown","metadata":{},"source":["- Pixel Transformations as operations performed in one pixel at a time. \n","- Histograms to display the distribution of intensities in an image. It can be used to optimize image characteristics. \n","- Intensity Transformations to make objects easier to see by improving image contrast and brightness. \n","- Thresholding to segment objects in images."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### `Geometric Transformations`\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### `Spatial Filtering` "]}],"metadata":{"kernelspec":{"display_name":"deepLearningMethods","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
