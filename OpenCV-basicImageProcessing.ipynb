{"cells":[{"cell_type":"markdown","metadata":{},"source":["# OpenCV Library\n","\n","Basic image processing.\n"]},{"cell_type":"markdown","metadata":{},"source":["Image processing and computer vision tasks include displaying, cropping, flipping, rotating,  image segmentation, classification, image restoration,  image recognition, image generation.  "]},{"cell_type":"markdown","metadata":{},"source":["<ul>\n","    <li>In this notebook:\n","        <ul>\n","            <li>Importing and getting information about images   </li>\n","            <li>Histograms, Intensity Transformations  </li>\n","            <li>Geometric Transformations</li>\n","            <li>Spatial Filtering </li>\n","        </ul>\n","    </li>\n","    \n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n"]},{"cell_type":"markdown","metadata":{},"source":["Images used in the notebook:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/barbara.png -O barbara.png  \n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/goldhill.bmp -O goldhill.bmp\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/cameraman.jpeg -O cameraman.jpeg\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/zelda.png -O zelda.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/mammogram.png -O mammogram.png"]},{"cell_type":"markdown","metadata":{},"source":["Helper function to concatenate two images side-by-side. "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def get_concat_h(im1, im2):\n","    #https://note.nkmk.me/en/python-pillow-concat-images/\n","    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n","    dst.paste(im1, (0, 0))\n","    dst.paste(im2, (im1.width, 0))\n","    return dst"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["my_image = \"lenna.png\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\Alberto\\\\Desktop\\\\github\\\\deep-learning-methods'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# checking current path\n","import os\n","cwd = os.getcwd()\n","cwd "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\Alberto\\\\Desktop\\\\github\\\\deep-learning-methods\\\\lenna.png'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# checking path of the image\n","image_path = os.path.join(cwd, my_image)\n","image_path\n"]},{"cell_type":"markdown","metadata":{},"source":["### `Importing and getting information about images`\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["The <code>imread()</code> method loads an image from the specified file, the input is the <code>path</code> of the image to be read, the <code>flag</code> paramter specifies how the image should be read, and the default value is <code>cv2.IMREAD_COLOR</code>.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["image = cv2.imread(my_image)\n","\n","# to load the image using the path\n","# image = cv2.imread(image_path)\n","# image.shape"]},{"cell_type":"markdown","metadata":{},"source":["The result is a numpy array with intensity values as 8-bit unsigned integers. \n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["type(image)"]},{"cell_type":"markdown","metadata":{},"source":["Shape of the array from the `shape` attribute.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(512, 512, 3)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["image.shape"]},{"cell_type":"markdown","metadata":{},"source":["Other libraries such as PIL return images in (R, G, B) format whereas OpenCV returns in (B, G, R) format.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["255"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["image.max()"]},{"cell_type":"markdown","metadata":{},"source":["and\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["3"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["image.min()"]},{"cell_type":"markdown","metadata":{},"source":["OpenCV's `imshow` function can open images in a new window, but this may bring problems in Jupyter:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#cv2.imshow('image', imgage)\n","#cv2.waitKey(0)\n","#cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["Using the `imshow` function from the `matplotlib` library:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Changing the color space with conversion code and the function `cvtColor` from the `cv2` library:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Grayscale images have pixel values representing the amount of light or intensity. Light shades of gray have a high-intensity darker shades have a lower intensity. White has the highest intensity, and black the lowest. \n","\n","To convert an image to Gray Scale using a color conversion code there is the function <code>cvtColor</code> and the parameter <code>cv2.COLOR_BGR2GRAY</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"]},{"cell_type":"markdown","metadata":{},"source":["The image array has only two dimensions, i.e. only one color channel:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_gray.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to save the grayscale image\n","cv2.imwrite('lena_gray_cv.jpg', image_gray)"]},{"cell_type":"markdown","metadata":{},"source":["To load a grayscale image `cv2.imread()` needs the gray color conversation code <code>cv2.COLOR_BGR2GRAY</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_gray = cv2.imread('barbara.png', cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"markdown","metadata":{},"source":["Working with different color channels.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon=cv2.imread('baboon.png')\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Getting the separate RGB channels and assigning them to the variables <code>blue</code>, <code>green</code>, and <code>red</code>, in (B, G, R) format.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["blue, green, red = baboon[:, :, 0], baboon[:, :, 1], baboon[:, :, 2]"]},{"cell_type":"markdown","metadata":{},"source":["Concatenating each image channel using the function <code>vconcat</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_bgr = cv2.vconcat([blue, green, red])"]},{"cell_type":"markdown","metadata":{},"source":["Plotting the color image next to the red channel in grayscale.\n","Regions with red have higher intensity values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.title(\"RGB image\")\n","plt.subplot(122)\n","plt.imshow(im_bgr,cmap='gray')\n","plt.title(\"Different color channels  blue (top), green (middle), red (bottom)  \")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can use numpy slicing to return the first 256 rows corresponding to the top half of the image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rows = 256"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image[0:rows,:,:])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Or to the first 256 columns corresponding to the left half of the image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["columns = 256"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.imshow(new_image[:,0:columns,:])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["To reassign an array to another variable, use the `copy` method."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["A = new_image.copy()\n","plt.imshow(A)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["If the method `copy()` is not applyied, the variable will point to the same location in memory.\n"]},{"cell_type":"markdown","metadata":{},"source":["Manipulating elements by index. Below, the red channel of the new array `baboon_red` is set to zero making the image look red.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon_red = baboon.copy()\n","baboon_red[:, :, 0] = 0\n","baboon_red[:, :, 1] = 0\n","plt.figure(figsize=(10, 10))\n","plt.imshow(cv2.cvtColor(baboon_red, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### `Histograms, Intensity Transformations`  \n"]},{"cell_type":"markdown","metadata":{},"source":["- Pixel Transformations as operations performed in one pixel at a time. \n","- Histograms to display the distribution of intensities in an image. It can be used to optimize image characteristics. \n","- Intensity Transformations to make objects easier to see by improving image contrast and brightness. \n","- Thresholding to segment objects in images."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Helper function to plot two images side-by-side.\n","def plot_image(image_1, image_2,title_1=\"Orignal\", title_2=\"New Image\"):\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(image_1,cmap=\"gray\")\n","    plt.title(title_1)\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(image_2,cmap=\"gray\")\n","    plt.title(title_2)\n","    plt.show()\n","\n","# Helper function to plot two histograms side-by-side\n","def plot_hist(old_image, new_image,title_old=\"Orignal\", title_new=\"New Image\"):\n","    intensity_values=np.array([x for x in range(256)])\n","    plt.subplot(1, 2, 1)\n","    plt.bar(intensity_values, cv2.calcHist([old_image],[0],None,[256],[0,256])[:,0],width = 5)\n","    plt.title(title_old)\n","    plt.xlabel('intensity')\n","    plt.subplot(1, 2, 2)\n","    plt.bar(intensity_values, cv2.calcHist([new_image],[0],None,[256],[0,256])[:,0],width = 5)\n","    plt.title(title_new)\n","    plt.xlabel('intensity')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["A histogram counts the number of occurrences per pixel for each intensity value. It's a useful tool for understanding and manipulating images.\n","\n","<code>cv.calcHist()</code> is used to generate a histogram. \n","\n","Here are the parameter values:\n","<p>\n","    <code>cv2.calcHist(\n","                        CV array:<b>[image]</b>,\n","                        image channel:<b>[0]</b>,\n","                        <b>[None]</b>,\n","                        number of bins:<b>[L]</b>,\n","                        index range of bins:<b>[0,L-1]</b>) </code>   \n","</p>\n","For real images, <code>L</code> is <code>256</code>."]},{"cell_type":"markdown","metadata":{},"source":["Histogram of a toy array with intensity values ranging from 0 to 2. Its first element is the number of zeros in the image (in this case, 1); its second element is the number of ones in the image (in this case, 5)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["toy_image = np.array([[0,2,2],[1,1,1],[1,1,2]],dtype=np.uint8)\n","plt.imshow(toy_image, cmap=\"gray\")\n","plt.show()\n","print(\"toy_image:\",toy_image)"]},{"cell_type":"markdown","metadata":{},"source":["The <code>caclHist</code> function calculates the histogram, in this case, there are only three bins for the three values. The index of the bins range from 1 to 3."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.bar([x for x in range(6)],[1,5,2,0,0,0])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### `Geometric Transformations`\n"]},{"cell_type":"markdown","metadata":{},"source":["**Geometric Operations:**\n","\n","- Scaling\n","- Translation\n","- Rotation\n","\n","\n","**Mathematical Operations:**\n","\n","- Array Operations\n","- Matix Operations\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### `Spatial Filtering` "]},{"cell_type":"markdown","metadata":{},"source":["- Filtering Noise\n","- Gaussian Blur\n","- Image Sharpening\n","- Edges\n","- Median\n","- Threshold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"deepLearningMethods","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
